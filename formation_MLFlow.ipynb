{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formation ML Flow\n",
    "\n",
    "L'objectif de cette formation est de vous apprendre à utiliser ML Flow, un dashboard pour expériences de Machine Learning. Cette formation vous montrera pas à pas comment lancer une expérience de Machine Learning et surveiller les paramètres, métriques et resultats de votre expérience grâce à ML Flow. \n",
    "\n",
    "Pour cela, la formation s'appuiera sur le célèbre jeu de donnée Iris, qui classifie 150 echantillons de fleur en 3 espèces d'iris : Iris setosa, Iris versicolor et Iris virginica. Le dataset comprend les caractéristiques de chaque échantillon (longueur et largeur des pétales et longueur et largeur des sépales) et nous allons donc essayer de créer plusieurs modèles qui essaieront de classifier les échantillons d'iris selon leurs caractéristiques. \n",
    "\n",
    "Commençons par importer les librairies qui vont nous servir :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouverture et visualisation du dataset Iris\n",
    "\n",
    "A présent ouvrons le fichier contenant le dataset et affichons les données concernant les 5 premiers échantillons :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('iris.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons maintenant quelques informations sur les caractéristiques des fleurs :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons le nombre d'échantillons pour chacune des espèces d'iris :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('class').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons maintenant le nuage de points de chaque paire de caractéristiques. Sur la diagonale, on retrouve un histogramme du nombre d'échantillons selon la valeur de la caractéristique. On peut remarquer certaines structures, par exemple des groupes, dans les relations entre certaines caractéristiques."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set(style=\"ticks\")\n",
    "    sns.pairplot(dataset, hue=\"class\")\n",
    "except ImportError:\n",
    "    print('Seaborn not available, plot with matplotlib instead')\n",
    "    pd.plotting.scatter_matrix(dataset,figsize=(15,7))\n",
    "plt.suptitle('Scatter matrix of the Iris dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Flow : premiers pas avec un modèle aléatoire\n",
    "\n",
    "Nous allons maintenant réaliser un premier exemple de modèle de classification très simple : le modèle aléatoire. Ce modèle attribuera aléatoirement une classe à chaque échantillon du dataset. Nous visualiserons ensuite ses performances (pas très bonnes, on l'imagine) avec ML FLow.\n",
    "\n",
    "Commençons par séparer le dataset en 2 variables : les 4 caractéristiques d'une part (X), et l'espèce d'iris d'autre part (Y)."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons notre modèle aléatoire :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy=\"uniform\")\n",
    "dummy.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons ses prédictions pour les premiers échantillons :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = dummy.predict(X)\n",
    "for i in range(5):\n",
    "    print(X[i], ', vraie classe : ', Y[i], ', prédiction : ', Y_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant enregistrer les performances de ce magnifique modèle avec ML Flow. Pour l'instant executez les cellules suivantes \"bêtement\", nous expliquerons chaque ligne ensuite."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='Modele_Aleatoire'):\n",
    "    mlflow.log_param('MODEL_NAME', 'DummyClassifier')\n",
    "    mlflow.log_metric('Accuracy', accuracy_score(Y, Y_pred))\n",
    "    mlflow.log_artifact('iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant ouvrez un terminal et naviguez jusqu'au dossier ```formation-mlflow```. Affichez le contenu du dossier. Vous devriez y trouver un nouveau dossier nommé ```mlflow```. Ce dossier contient toutes les informations que nous avons enregistré précédemment.\n",
    "\n",
    "Toujours dans le dossier ```formation-mlflow```, entrez la commande ```mlflow ui```. Le message ```Serving on http://XXXXXXX:5000``` devrait s'afficher. Ouvrez maintenant un navigateur web et ouvrez une fenêtre vers l'url ```http://localhost:5000/```. Vous devriez voir apparaître le dashboard suivant :\n",
    "\n",
    "![dashboard](MLFlow.png)\n",
    "\n",
    "La ligne au milieu du tableau, comportant le nom ```Modele_Aleatoire``` correspond aux données que nous avons enregistré précédemment. Vous pouvez remarquer dans la colonne ```Parameters``` le paramètre  ```MODEL_NAME``` que nous avons enregistré, ainsi que la métrique ```Accuracy``` dans la colonne ```Metrics```. Maintenant cliquez sur cette ligne et vous trouverez le détail des informations concernant ce ```run```. Descendez jusqu'à la section ```Artifacts``` où vous pourrez voir une copie du fichier ```iris.csv```. En cliquant dessus vous pourrez le visualiser en entier.\n",
    "\n",
    "Revenons maintenant sur la façon dont nous avons enregistré ces informations avec ML FLow.\n",
    "\n",
    "ML Flow permet d'enregistrer puis visualiser 3 types de choses :\n",
    "* des **paramètres** : ce sont des valeurs (int, float, string, ...) qui ne varient pas au cours d'un 'run', ici ```MODEL_NAME``` est un paramètre.\n",
    "* des **métriques** : ce sont des valeurs numériques qui peuvent varier au cours du 'run', ici ```Accuracy``` est une métrique.\n",
    "* des **fichiers** : ces fichiers peuvent prendre n'importe quelle forme (png, jpeg, gif, txt, ...) et ne sont pas modifiables au cours du 'run. Ici nous avons fait une copie du fichier ```iris.csv```.\n",
    "\n",
    "Toutes ces variables sont regroupées dans un même 'run', ici nommé 'Modele_Aleatoire'. Un 'run' correspond à une ligne du tableau. Les 'runs' peuvent être regroupés en 'experiences', ici nommée ```Default``` dans la colonne de gauche. Nous verons comment changer le nom de l'expérience par la suite.\n",
    "\n",
    "Reprenons les lignes de code qui nous ont permis de faire tout ça :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Création du 'run' ML FLow, nommé ici 'Modele_Aleatoire'\n",
    "#    Tous les paramètres, métriques ou fichiers que nous enregistrerons ensuite\n",
    "#    seront enregistré dans ce 'run', qui correspond à une ligne du tableau\n",
    "with mlflow.start_run(run_name='Modele_Aleatoire'):\n",
    "\n",
    "    # 2. Enregistrement d'un paramètre\n",
    "    mlflow.log_param('MODEL_NAME', 'DummyClassifier')\n",
    "\n",
    "    # 3. Enregistrement d'une métrique\n",
    "    mlflow.log_metric('Accuracy', accuracy_score(Y, Y_pred))\n",
    "\n",
    "    # 4. Enregistrement d'un fichier\n",
    "    mlflow.log_artifact('iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant entraîner différents modèles sur le jeu de données et voir comment nous pouvons les comparer facilement avec ML FLow.\n",
    "\n",
    "## ML Flow : Comparaison de plusieurs modèles\n",
    "\n",
    "Nous allons maintenant créer plusieurs modèles et estimer leurs performances sur des données qu'ils n'ont pas vu pendant l'entraînement. Commençons par séparer notre dataset en deux parties : une pour l'entraînement et une pour le test."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons la liste des modèles à tester :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = []\n",
    "models.append(('LogisticRegression', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "models.append(('GaussianNB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutons cette fonction qui va nous permettre de tracer de jolies matrices de confusion par la suite :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names, title, \n",
    "                          normalize=True, save_path='matrix.png'):\n",
    "    import itertools\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    cmap = plt.get_cmap('Blues')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'\\\n",
    "               .format(accuracy, misclass))\n",
    "    plt.gcf().canvas.draw()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant entraîner nos modèles et enregistrer leurs paramètres et métriques avec ML Flow. \n",
    "\n",
    "Nous allons voir deux nouvelles choses : \n",
    "* Comment créer une nouvelle expérience\n",
    "* Comment enregistrer plusieurs paramètres ou métriques d'un seul coup"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Création d'une nouvelle expérience\n",
    "#    Tous les nouveaux runs seront enregistrés dans cette expérience\n",
    "mlflow.set_experiment('Comparaison')\n",
    "\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "\n",
    "    # 2. Création et début d'un nouveau run\n",
    "    with mlflow.start_run(run_name=name):\n",
    "\n",
    "        # 3. Enregistrement de plusieurs paramètres sous forme d'un dictionnaire\n",
    "        params = {}\n",
    "        params['MODEL_NAME'] = name\n",
    "        params['TRAIN_SIZE'] = len(X_train)\n",
    "        params['TEST_SIZE'] = len(X_val)\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # On note le moment du début de l'expérience pour mesurer la durée de l'entraînement\n",
    "        start = time.time()\n",
    "\n",
    "        # Entraînement du modèle\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        training_time = time.time() - start\n",
    "\n",
    "        predictions = model.predict(X_val)\n",
    "\n",
    "        # 4. Enregistrement de plusieurs métriques sous forme d'un dictionnaire\n",
    "        metrics = {}\n",
    "        metrics['Accuracy'] = accuracy_score(Y_val, predictions)\n",
    "        metrics['Precision'] = precision_score(Y_val, predictions, average='macro')\n",
    "        metrics['Recall'] = recall_score(Y_val, predictions, average='macro')\n",
    "        metrics['Training Time'] = training_time\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # 5. Enregistrement de la matrice de confusion\n",
    "        cm = confusion_matrix(Y_val, predictions)\n",
    "        plot_confusion_matrix(cm, ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'],\n",
    "                              'Confusion matrix '+name)\n",
    "        mlflow.log_artifact('matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrounez maintenant sur votre navigateur pour voir le résultat dans le dashboard ML Flow.\n",
    "\n",
    "Vous devriez voir une nouvelle expérience 'Comparaison' dans la liste des expériences à gauche. En cliquant dessus vous pourrez voir apparaître les 6 runs que nous venons de lancer. Selectionnez les tous et cliquez sur ```Compare```. Vous pouvez maintenant facilement comparer toutes les caractéristiques de nos modèles. En cliquant sur le nom d'une des métriques vous pourrez afficher un diagramme comparant les valeurs pour tous les modèles.\n",
    "\n",
    "Revenez au tableau des runs et ouvrer l'un des runs. Dans la partie ```Artifacts``` vous pourrez voir la superbe matrice de confusion que nous avons tracé."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Flow : Enregistrer l'évolution d'une métrique\n",
    "\n",
    "Dans cette dernière partie, nous allons voir comment enregistrer l'évolution d'une métrique au cours du temps. Pour cela, nous allons utiliser comme modèle un réseau de neurones basique : le perceptron multi-couches.\n",
    "\n",
    "Afin de calculer nos métriques au cours de l'entrainement, nous decoupons celui-ci en plusieurs epochs. A chaque epoch, le reseau de neurone s'entraîne une fois sur l'intégralité du dataset. Tout ceci est fait automatiquement dans la fonction ```fit``` par défaut de scikit learn, mais nous allons faire les choses manuellement ici, pour visualiser l'évolution des métriques au cours de l'apprentissage."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 1. Création et début d'un nouveau run\n",
    "with mlflow.start_run(run_name='Multilayer Perceptron'):\n",
    "\n",
    "    model = MLPClassifier(max_iter=10)\n",
    "    mlflow.log_param('MODEL_NAME', 'MLPClassifier')\n",
    "\n",
    "    N_TRAIN_SAMPLES = X_train.shape[0]\n",
    "    N_EPOCHS = 50\n",
    "    N_BATCH = 8\n",
    "    N_CLASSES = np.unique(Y_train)\n",
    "    scores_train = []\n",
    "    scores_test = []\n",
    "\n",
    "    # EPOCH\n",
    "    epoch = 0\n",
    "    while epoch < N_EPOCHS:\n",
    "        if epoch % 5 == 0 : print('Epoch: ', epoch)\n",
    "        # SHUFFLING\n",
    "        random_perm = np.random.permutation(X_train.shape[0])\n",
    "        mini_batch_index = 0\n",
    "        while True:\n",
    "            # TRAIN ON MINI-BATCH\n",
    "            indices = random_perm[mini_batch_index:mini_batch_index + N_BATCH]\n",
    "            model.partial_fit(X_train[indices], Y_train[indices], classes=N_CLASSES)\n",
    "            mini_batch_index += N_BATCH\n",
    "            if mini_batch_index >= N_TRAIN_SAMPLES:\n",
    "                break\n",
    "\n",
    "        metrics = {}\n",
    "        predictions = model.predict(X_val)\n",
    "        metrics['Accuracy'] = accuracy_score(Y_val, predictions)\n",
    "        metrics['Precision'] = precision_score(Y_val, predictions, average='macro')\n",
    "        metrics['Recall'] = recall_score(Y_val, predictions, average='macro')\n",
    "        metrics['Loss'] = model.loss_\n",
    "        # 2. Enregistrement de plusieurs métriques pour une epoch donnée\n",
    "        mlflow.log_metrics(metrics, step=epoch)\n",
    "\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenez sur le tableau des runs dans le dashboard et ouvrez le run que nous venons de créer. En cliquant sur l'une des métriques, vous pourrez voir son évolution au cours de l'apprentissage du réseau de neurones."
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}